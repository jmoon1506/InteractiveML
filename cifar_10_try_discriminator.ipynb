{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "from enum import Enum\n",
    "\n",
    "class FLAGS(Enum):\n",
    "    batch_size = 128\n",
    "    data_dir = './cifar10_data_karishma'\n",
    "    use_fp16 = False\n",
    "    train_dir = './cifar10_train_karishma'\n",
    "    max_steps = 30000\n",
    "    log_device_placement = False\n",
    "    log_frequency = 10\n",
    "\n",
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_SIZE = 24\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "\n",
    "def read_cifar10(filename_queue):\n",
    "  \"\"\"Reads and parses examples from CIFAR10 data files.\n",
    "\n",
    "  Recommendation: if you want N-way read parallelism, call this function\n",
    "  N times.  This will give you N independent Readers reading different\n",
    "  files & positions within those files, which will give better mixing of\n",
    "  examples.\n",
    "\n",
    "  Args:\n",
    "    filename_queue: A queue of strings with the filenames to read from.\n",
    "\n",
    "  Returns:\n",
    "    An object representing a single example, with the following fields:\n",
    "      height: number of rows in the result (32)\n",
    "      width: number of columns in the result (32)\n",
    "      depth: number of color channels in the result (3)\n",
    "      key: a scalar string Tensor describing the filename & record number\n",
    "        for this example.\n",
    "      label: an int32 Tensor with the label in the range 0..9.\n",
    "      uint8image: a [height, width, depth] uint8 Tensor with the image data\n",
    "  \"\"\"\n",
    "\n",
    "  class CIFAR10Record(object):\n",
    "    pass\n",
    "  result = CIFAR10Record()\n",
    "\n",
    "  # Dimensions of the images in the CIFAR-10 dataset.\n",
    "  # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "  # input format.\n",
    "  label_bytes = 1  # 2 for CIFAR-100\n",
    "  result.height = 32\n",
    "  result.width = 32\n",
    "  result.depth = 3\n",
    "  image_bytes = result.height * result.width * result.depth\n",
    "  # Every record consists of a label followed by the image, with a\n",
    "  # fixed number of bytes for each.\n",
    "  record_bytes = label_bytes + image_bytes\n",
    "\n",
    "  # Read a record, getting filenames from the filename_queue.  No\n",
    "  # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "  # and footer_bytes at their default of 0.\n",
    "  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "  result.key, value = reader.read(filename_queue)\n",
    "\n",
    "  # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "  record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "  # The first bytes represent the label, which we convert from uint8->int32.\n",
    "  result.label = tf.cast(\n",
    "      tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "  # The remaining bytes after the label represent the image, which we reshape\n",
    "  # from [depth * height * width] to [depth, height, width].\n",
    "  depth_major = tf.reshape(\n",
    "      tf.strided_slice(record_bytes, [label_bytes],\n",
    "                       [label_bytes + image_bytes]),\n",
    "      [result.depth, result.height, result.width])\n",
    "  # Convert from [depth, height, width] to [height, width, depth].\n",
    "  result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "  \"\"\"Construct a queued batch of images and labels.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "    label: 1-D Tensor of type.int32\n",
    "    min_queue_examples: int32, minimum number of samples to retain\n",
    "      in the queue that provides of batches of examples.\n",
    "    batch_size: Number of images per batch.\n",
    "    shuffle: boolean indicating whether to use a shuffling queue.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  # Create a queue that shuffles the examples, and then\n",
    "  # read 'batch_size' images + labels from the example queue.\n",
    "  num_preprocess_threads = 16\n",
    "  if shuffle:\n",
    "    images, label_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue=min_queue_examples)\n",
    "  else:\n",
    "    images, label_batch = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "  # Display the training images in the visualizer.\n",
    "  tf.summary.image('images', images)\n",
    "\n",
    "  return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs_overloaded(data_dir, batch_size):\n",
    "  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "\n",
    "  Args:\n",
    "    data_dir: Path to the CIFAR-10 data directory.\n",
    "    batch_size: Number of images per batch.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "               for i in xrange(1, 6)]\n",
    "  for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "  # Create a queue that produces the filenames to read.\n",
    "  filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "  # Read examples from files in the filename queue.\n",
    "  read_input = read_cifar10(filename_queue)\n",
    "  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "  height = IMAGE_SIZE\n",
    "  width = IMAGE_SIZE\n",
    "\n",
    "  # Image processing for training the network. Note the many random\n",
    "  # distortions applied to the image.\n",
    "\n",
    "  # Randomly crop a [height, width] section of the image.\n",
    "  distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "\n",
    "  # Randomly flip the image horizontally.\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "  # Because these operations are not commutative, consider randomizing\n",
    "  # the order their operation.\n",
    "  # NOTE: since per_image_standardization zeros the mean and makes\n",
    "  # the stddev unit, this likely has no effect see tensorflow#1458.\n",
    "  distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "  distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "  # Set the shapes of tensors.\n",
    "  float_image.set_shape([height, width, 3])\n",
    "  read_input.label.set_shape([1])\n",
    "\n",
    "  # Ensure that the random shuffling has good mixing properties.\n",
    "  min_fraction_of_examples_in_queue = 0.4\n",
    "  min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "  print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "  # Generate a batch of images and labels by building up a queue of examples.\n",
    "  return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "\n",
    "def inputs_overloaded(eval_data, data_dir, batch_size):\n",
    "  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "\n",
    "  Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "    data_dir: Path to the CIFAR-10 data directory.\n",
    "    batch_size: Number of images per batch.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  if not eval_data:\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                 for i in xrange(1, 6)]\n",
    "    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "  else:\n",
    "    filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "  for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "  # Create a queue that produces the filenames to read.\n",
    "  filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "  # Read examples from files in the filename queue.\n",
    "  read_input = read_cifar10(filename_queue)\n",
    "  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "  height = IMAGE_SIZE\n",
    "  width = IMAGE_SIZE\n",
    "\n",
    "  # Image processing for evaluation.\n",
    "  # Crop the central [height, width] of the image.\n",
    "  resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
    "                                                         height, width)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "  # Set the shapes of tensors.\n",
    "  float_image.set_shape([height, width, 3])\n",
    "  read_input.label.set_shape([1])\n",
    "\n",
    "  # Ensure that the random shuffling has good mixing properties.\n",
    "  min_fraction_of_examples_in_queue = 0.4\n",
    "  min_queue_examples = int(num_examples_per_epoch *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "\n",
    "  # Generate a batch of images and labels by building up a queue of examples.\n",
    "  return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "from enum import Enum\n",
    "\n",
    "#import cifar10_input\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# # Basic model parameters.\n",
    "# parser.add_argument('--batch_size', type=int, default=128,\n",
    "#                     help='Number of images to process in a batch.')\n",
    "\n",
    "# parser.add_argument('--data_dir', type=str, default='/tmp/cifar10_data',\n",
    "#                     help='Path to the CIFAR-10 data directory.')\n",
    "\n",
    "# parser.add_argument('--use_fp16', type=bool, default=False,\n",
    "#                     help='Train the model using fp16.')\n",
    "\n",
    "# FLAGS = parser.parse_args()\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "# IMAGE_SIZE = cifar10_input.IMAGE_SIZE\n",
    "# NUM_CLASSES = cifar10_input.NUM_CLASSES\n",
    "# NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "# NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.\n",
    "\n",
    "# If a model is trained with multiple GPUs, prefix all Op names with tower_name\n",
    "# to differentiate the operations. Note that this prefix is removed from the\n",
    "# names of the summaries when visualizing a model.\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "\n",
    "def _activation_summary(x):\n",
    "  \"\"\"Helper to create summaries for activations.\n",
    "\n",
    "  Creates a summary that provides a histogram of activations.\n",
    "  Creates a summary that measures the sparsity of activations.\n",
    "\n",
    "  Args:\n",
    "    x: Tensor\n",
    "  Returns:\n",
    "    nothing\n",
    "  \"\"\"\n",
    "  # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "  # session. This helps the clarity of presentation on tensorboard.\n",
    "  tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "  tf.summary.histogram(tensor_name + '/activations', x)\n",
    "  tf.summary.scalar(tensor_name + '/sparsity',\n",
    "                                       tf.nn.zero_fraction(x))\n",
    "\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "  \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  with tf.device('/cpu:0'):\n",
    "    dtype = tf.float16 if FLAGS.use_fp16.value else tf.float32\n",
    "    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "  return var\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "  Note that the Variable is initialized with a truncated normal distribution.\n",
    "  A weight decay is added only if one is specified.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  dtype = tf.float16 if FLAGS.use_fp16.value else tf.float32\n",
    "  var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "  if wd is not None:\n",
    "    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "  return var\n",
    "\n",
    "\n",
    "def distorted_inputs():\n",
    "  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir.value:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir.value, 'cifar-10-batches-bin')\n",
    "  images, labels = distorted_inputs_overloaded(data_dir=data_dir,\n",
    "                                                  batch_size=FLAGS.batch_size.value)\n",
    "  if FLAGS.use_fp16.value:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "def inputs(eval_data):\n",
    "  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "\n",
    "  Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If no data_dir\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir.value:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "  data_dir = os.path.join(FLAGS.data_dir.value, 'cifar-10-batches-bin')\n",
    "  images, labels = inputs_overloaded(eval_data=eval_data,\n",
    "                                        data_dir=data_dir,\n",
    "                                        batch_size=FLAGS.batch_size.value)\n",
    "  if FLAGS.use_fp16.value:\n",
    "    images = tf.cast(images, tf.float16)\n",
    "    labels = tf.cast(labels, tf.float16)\n",
    "  return images, labels\n",
    "\n",
    "\n",
    "def inference(images):\n",
    "  \"\"\"Build the CIFAR-10 model.\n",
    "\n",
    "  Args:\n",
    "    images: Images returned from distorted_inputs() or inputs().\n",
    "\n",
    "  Returns:\n",
    "    Logits.\n",
    "  \"\"\"\n",
    "  # We instantiate all variables using tf.get_variable() instead of\n",
    "  # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "  # If we only ran this model on a single GPU, we could simplify this function\n",
    "  # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "  #\n",
    "  # conv1\n",
    "\n",
    "  #filter shape has height, width, channels, number of filters\n",
    "  \n",
    "  # Create list of layers\n",
    "  layers = {}\n",
    "  with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    # Add to list of layers\n",
    "    layers['conv1_pre_relu'] = pre_activation\n",
    "    conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "    layers['conv1'] = conv1\n",
    "\n",
    "  # pool1\n",
    "  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "  layers['pool1'] = pool1\n",
    "  # norm1\n",
    "  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "  layers['norm1'] = norm1\n",
    "\n",
    "  # conv2\n",
    "  with tf.variable_scope('conv2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 64, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    layers['conv2_pre_relu'] = pre_activation\n",
    "    conv2 = tf.nn.relu(pre_activation, name=scope.name)  \n",
    "    layers['conv2'] = conv2\n",
    "    _activation_summary(conv2)\n",
    "\n",
    "  # norm2\n",
    "  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "  layers['norm2'] = norm2\n",
    "  # pool2\n",
    "  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "  layers['pool2'] = pool2\n",
    "\n",
    "  # local3\n",
    "  with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    reshape = tf.reshape(pool2, [FLAGS.batch_size.value, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.matmul(reshape, weights) + biases\n",
    "    layers['local3_pre_relu'] = pre_activation\n",
    "    local3 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    layers['local3'] = local3\n",
    "\n",
    "    _activation_summary(local3)\n",
    "\n",
    "  # local4\n",
    "  with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.matmul(local3, weights) + biases\n",
    "    layers['local4_pre_relu'] = pre_activation\n",
    "    local4 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    layers['local4'] = local4\n",
    "    _activation_summary(local4)\n",
    "\n",
    "  # linear layer(WX + b),\n",
    "  # We don't apply softmax here because\n",
    "  # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "  # and performs the softmax internally for efficiency.\n",
    "  with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                          stddev=1/192.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    layers['soft_max_out'] = softmax_linear\n",
    "    _activation_summary(softmax_linear)\n",
    "\n",
    "  return softmax_linear, layers\n",
    "  #return softmax_linear\n",
    "\n",
    "\n",
    "def discriminator(images):\n",
    "  \"\"\"Build the CIFAR-10 discriminator.\n",
    "\n",
    "  Args:\n",
    "    images: Images returned from distorted_inputs() or inputs().\n",
    "\n",
    "  Returns:\n",
    "    Logits.\n",
    "  \"\"\"\n",
    "  # We instantiate all variables using tf.get_variable() instead of\n",
    "  # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "  # If we only ran this model on a single GPU, we could simplify this function\n",
    "  # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "  #\n",
    "  # conv1\n",
    "\n",
    "  #filter shape has height, width, channels, number of filters\n",
    "  \n",
    "  # Create list of layers\n",
    "  with tf.variable_scope('discriminator') as scope:\n",
    "      with tf.variable_scope('conv1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[5, 5, 3, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "      # pool1\n",
    "      pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                             padding='SAME', name='pool1')\n",
    "      # norm1\n",
    "      norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                        name='norm1')\n",
    "\n",
    "      # conv2\n",
    "      with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights',\n",
    "                                             shape=[5, 5, 64, 64],\n",
    "                                             stddev=5e-2,\n",
    "                                             wd=0.0)\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)  \n",
    "\n",
    "      # norm2\n",
    "      norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                        name='norm2')\n",
    "      # pool2\n",
    "      pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                             strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "      # local3\n",
    "      with tf.variable_scope('local3') as scope:\n",
    "        # Move everything into depth so we can perform a single matrix multiply.\n",
    "        reshape = tf.reshape(pool2, [FLAGS.batch_size.value, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                              stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.matmul(reshape, weights) + biases\n",
    "        local3 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "      # local4\n",
    "      with tf.variable_scope('local4') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                              stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.matmul(local3, weights) + biases\n",
    "        local4 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "      # linear layer(WX + b),\n",
    "      # We don't apply softmax here because\n",
    "      # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "      # and performs the softmax internally for efficiency.\n",
    "      with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [192, 2],\n",
    "                                              stddev=1/192.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [2],\n",
    "                                  tf.constant_initializer(0.0))\n",
    "        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "\n",
    "  return softmax_linear\n",
    "  #return softmax_linear\n",
    "\n",
    "def loss(logits, labels):\n",
    "  \"\"\"Add L2Loss to all the trainable variables.\n",
    "\n",
    "  Add summary for \"Loss\" and \"Loss/avg\".\n",
    "  Args:\n",
    "    logits: Logits from inference().\n",
    "    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "            of shape [batch_size]\n",
    "\n",
    "  Returns:\n",
    "    Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  # Calculate the average cross entropy loss across the batch.\n",
    "  labels = tf.cast(labels, tf.int64)\n",
    "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "  tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "  # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "  # decay terms (L2 loss).\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "def _add_loss_summaries(total_loss):\n",
    "  \"\"\"Add summaries for losses in CIFAR-10 model.\n",
    "\n",
    "  Generates moving average for all losses and associated summaries for\n",
    "  visualizing the performance of the network.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "  Returns:\n",
    "    loss_averages_op: op for generating moving averages of losses.\n",
    "  \"\"\"\n",
    "  # Compute the moving average of all individual losses and the total loss.\n",
    "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "  losses = tf.get_collection('losses')\n",
    "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "  # Attach a scalar summary to all individual losses and the total loss; do the\n",
    "  # same for the averaged version of the losses.\n",
    "  for l in losses + [total_loss]:\n",
    "    # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "    # as the original loss name.\n",
    "    tf.summary.scalar(l.op.name + ' (raw)', l)\n",
    "    tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "\n",
    "  return loss_averages_op\n",
    "\n",
    "\n",
    "def cifar10_train(total_loss, global_step):\n",
    "  \"\"\"Train CIFAR-10 model.\n",
    "\n",
    "  Create an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "  Returns:\n",
    "    train_op: op for training.\n",
    "  \"\"\"\n",
    "  # Variables that affect learning rate.\n",
    "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size.value\n",
    "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "  # Decay the learning rate exponentially based on the number of steps.\n",
    "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "  tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "  # Generate moving averages of all losses and associated summaries.\n",
    "  loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "  # Compute gradients.\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "  # Apply gradients.\n",
    "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "  # Add histograms for trainable variables.\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "  # Add histograms for gradients.\n",
    "  for grad, var in grads:\n",
    "    if grad is not None:\n",
    "      tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "  # Track the moving averages of all trainable variables.\n",
    "  variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "  return train_op\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = FLAGS.data_dir.value\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "          float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "  if not os.path.exists(extracted_dir_path):\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## EVALUATION OF ACCURACY\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from enum import Enum\n",
    "\n",
    "class EVALFLAGS(Enum):\n",
    "    eval_dir = './cifar10_eval_karishma'\n",
    "    eval_data = 'test'\n",
    "    checkpoint_dir = './cifar10_train_karishma'\n",
    "    eval_interval_secs = 300\n",
    "    num_examples = 10000\n",
    "    run_once = False\n",
    "\n",
    "def eval_once(saver, summary_writer, top_k_op, summary_op):\n",
    "  \"\"\"Run Eval once.\n",
    "  Args:\n",
    "    saver: Saver.\n",
    "    summary_writer: Summary writer.\n",
    "    top_k_op: Top K op.\n",
    "    summary_op: Summary op.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(EVALFLAGS.checkpoint_dir.value)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      # Restores from checkpoint\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "      # Assuming model_checkpoint_path looks something like:\n",
    "      #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "      # extract global_step from it.\n",
    "      global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "    else:\n",
    "      print('No checkpoint file found')\n",
    "      return\n",
    "\n",
    "    # Start the queue runners.\n",
    "    coord = tf.train.Coordinator()\n",
    "    try:\n",
    "      threads = []\n",
    "      for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "        threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "      num_iter = int(math.ceil(EVALFLAGS.num_examples.value / FLAGS.batch_size.value))\n",
    "      true_count = 0  # Counts the number of correct predictions.\n",
    "      total_sample_count = num_iter * FLAGS.batch_size.value\n",
    "      step = 0\n",
    "      while step < num_iter and not coord.should_stop():\n",
    "        predictions = sess.run([top_k_op])\n",
    "        true_count += np.sum(predictions)\n",
    "        step += 1\n",
    "\n",
    "      # Compute precision @ 1.\n",
    "      precision = true_count / total_sample_count\n",
    "      print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "      summary = tf.Summary()\n",
    "      summary.ParseFromString(sess.run(summary_op))\n",
    "      summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "      summary_writer.add_summary(summary, global_step)\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "      coord.request_stop(e)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads, stop_grace_period_secs=10)\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "  \"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default() as g:\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    eval_data = EVALFLAGS.eval_data.value == 'test'\n",
    "    images, labels = inputs(eval_data=eval_data)\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits, layers = inference(images)\n",
    "\n",
    "    # Calculate predictions.\n",
    "    top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "    variables_to_restore = variable_averages.variables_to_restore()\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(EVALFLAGS.eval_dir.value, g)\n",
    "\n",
    "    while True:\n",
    "      eval_once(saver, summary_writer, top_k_op, summary_op)\n",
    "      if EVALFLAGS.run_once:\n",
    "        break\n",
    "      time.sleep(EVALFLAGS.eval_interval_secs.value)\n",
    "\n",
    "\n",
    "#def main(argv=None):  # pylint: disable=unused-argument\n",
    "#maybe_download_and_extract()\n",
    "if tf.gfile.Exists(EVALFLAGS.eval_dir.value):\n",
    "  tf.gfile.DeleteRecursively(EVALFLAGS.eval_dir.value)\n",
    "tf.gfile.MakeDirs(EVALFLAGS.eval_dir.value)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gradient(conv_layer, filter_index, batch_size, X):\n",
    "    if (len(conv_layer.shape) == 2):\n",
    "        # This is a fully connected layer with 2-dimentions\n",
    "        target_pixel = tf.slice(conv_layer, begin=[0, filter_index],size=[batch_size, 1])\n",
    "        grad = tf.gradients(target_pixel, X)\n",
    "        return grad, target_pixel\n",
    "    else:\n",
    "        # This is a convolutional layer with 4-dimentions\n",
    "        mid_height = conv_layer.get_shape().as_list()[1] // 2\n",
    "        mid_width = conv_layer.get_shape().as_list()[2] // 2\n",
    "        target_pixel = tf.slice(conv_layer, begin=[0, mid_height, mid_width, filter_index],size=[batch_size, 1, 1, 1])\n",
    "        grad = tf.gradients(target_pixel, X)\n",
    "        return grad, target_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gradient_multiple_filters(conv_layer, batch_size, X):\n",
    "    # This is a convolutional layer with 4-dimentions\n",
    "    mid_height = conv_layer.get_shape().as_list()[1] // 2\n",
    "    mid_width = conv_layer.get_shape().as_list()[2] // 2\n",
    "    num_filters = conv_layer.get_shape().as_list()[3]\n",
    "    grad = []\n",
    "    for i in range(batch_size):\n",
    "        filter_index = i % num_filters\n",
    "        target_pixel = tf.slice(conv_layer, begin=[i, mid_height, mid_width, filter_index],size=[1, 1, 1, 1])\n",
    "        grad.append(tf.gradients(target_pixel, X)[0][i])\n",
    "    return tf.stack(grad), target_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_discriminator = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    eval_data = EVALFLAGS.eval_data.value == 'test'\n",
    "    X = tf.placeholder(tf.float32, [FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    X_dis = tf.placeholder(tf.float32, [FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    true_Y_dis = tf.placeholder(tf.float32, [None, 2])\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits, layers = inference(X)\n",
    "    dis_logist = discriminator(X_dis)\n",
    "    # Build the loss for discriminator\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        dis_prediction = tf.nn.softmax(dis_logist)\n",
    "        loss_dis = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=dis_logist, labels=true_Y_dis))\n",
    "        ### ?? Up to which point should we find the gradient?\n",
    "        score_dis = -tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=dis_logist, labels=true_Y_dis))\n",
    "        opt_dis = tf.train.AdamOptimizer(learning_rate=learning_rate_discriminator)\n",
    "        train_dis = opt_dis.minimize(loss_dis)\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "    variables_to_restore = variable_averages.variables_to_restore()\n",
    "    # Filter out discriminator variables and restore only classifier variable\n",
    "    classifier_variables_to_restore = {k:variables_to_restore[k] for k in variables_to_restore if k[0:13] != 'discriminator'}\n",
    "    saver = tf.train.Saver(classifier_variables_to_restore)\n",
    "    \n",
    "    # Start the session\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(EVALFLAGS.checkpoint_dir.value)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      # Restores from checkpoint\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "      # Assuming model_checkpoint_path looks something like:\n",
    "      #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "      # extract global_step from it.\n",
    "      global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "    else:\n",
    "      print('No checkpoint file found')\n",
    "    conv_weights = g.get_tensor_by_name('conv1/weights:0')\n",
    "    last_weights = g.get_tensor_by_name('softmax_linear/weights:0')\n",
    "    true_images, _ = inputs(eval_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = sess.run(true_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent on Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_maximization(sess, conv_layer, to_display = False, reg = 1, \n",
    "                            learning_rate_class = 0.0001, steps = 100, noise_coeff = 0.1, true_weights = None):\n",
    "    gradient, target_pixel = find_gradient_multiple_filters(conv_layer, FLAGS.batch_size.value, X)\n",
    "    n = 10\n",
    "    canvas = np.empty((IMAGE_SIZE * n, IMAGE_SIZE * n, 3))    \n",
    "    accumulateClassifier = np.zeros((FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    noise_img = np.random.rand(FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    img = noise_img\n",
    "    accumulateClassifier[:, :, :, :] = 0\n",
    "    loss = []\n",
    "    objectives = []\n",
    "    for k in range(steps):\n",
    "        for inter_loop in range(10):\n",
    "            g, activation = sess.run([gradient, target_pixel], feed_dict={X: img, X_dis:img})\n",
    "            # Accumulate and Normalize the gradient\n",
    "            grad_reg = g - reg*img\n",
    "            accumulateClassifier = 0.1 * grad_reg ** 2 + 0.9 * accumulateClassifier \n",
    "            normalized_class_grad = grad_reg / np.sqrt(accumulateClassifier + 1e-8)\n",
    "            # Add the gradient from classifier\n",
    "            noise = np.random.normal(size=(FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "            img += (learning_rate_class) * (normalized_class_grad + noise_coeff*noise)\n",
    "        # Calculated the loss if the desired input in given for first layer\n",
    "        if (true_weights is not None):\n",
    "            mean_batch = np.mean(img, axis = 0)\n",
    "            this_loss = np.sum(np.square(mean_batch[10:15,10:15,:]*reg - true_weights))\n",
    "            loss.append(this_loss)\n",
    "        this_objective = np.sum(activation - reg*np.sqrt(np.sum(np.square(img), axis = (1,2,3)))/2)\n",
    "        objectives.append(this_objective)\n",
    "        # Display the image\n",
    "        if (to_display):\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    # Draw the generated digits\n",
    "                    canvas[i * IMAGE_SIZE:(i + 1) * IMAGE_SIZE, j * IMAGE_SIZE:(j + 1) * IMAGE_SIZE, :] = img[i * n + j]\n",
    "            plt.figure(figsize=(n, n))\n",
    "            plt.imshow(canvas)\n",
    "            plt.show()\n",
    "            print('iter=' + str(k))\n",
    "            print('Class Gradient range  =' + str(np.min(normalized_class_grad)) + \" \" + str(np.max(normalized_class_grad)))\n",
    "            display.clear_output(wait=True)\n",
    "            time.sleep(0.2)\n",
    "        \n",
    "    return img, loss, objectives, canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(FLAGS.data_dir.value, 'cifar-10-batches-bin')\n",
    "filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "           for i in xrange(1, 6)]\n",
    "for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "# Create a queue that produces the filenames to read.\n",
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "# Read examples from files in the filename queue.\n",
    "read_input = read_cifar10(filename_queue)\n",
    "reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10Copy as cifar10Copy\n",
    "mages_train, cls_train, labels_train = cifar10Copy.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual filter of first layers\n",
    "first_layer = sess.run(conv_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first layer\n",
    "re = 1\n",
    "lr = 5e-3\n",
    "indexes = range(64)\n",
    "indexes.append(range(64))\n",
    "img, losses, objectives, canvas = activation_maximization(sess, layers['conv1_pre_relu'], \n",
    "                                                          to_display = True, reg = re, \n",
    "                                                          learning_rate_class = lr, steps = 50, noise_coeff = 0)\n",
    "# Get the average gradient descent result of a batch\n",
    "mean_batch = np.mean(img, axis = 0)\n",
    "# Plot\n",
    "plt.imshow(canvas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(objectives)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 63\n",
    "plt.imshow(img[i])\n",
    "plt.show()\n",
    "plt.imshow(first_layer[:,:,:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True image will have prediction (1, 0), fake image will have prediction(0, 1)\n",
    "y_fake = np.zeros((FLAGS.batch_size.value, 2))\n",
    "y_real = np.zeros((FLAGS.batch_size.value, 2))\n",
    "y_fake[:,1] = 1\n",
    "y_real[:,0] = 1\n",
    "# First half is fake image, second half is real image\n",
    "y_half = np.zeros((FLAGS.batch_size.value, 2))\n",
    "y_half[:FLAGS.batch_size.value//2, 1] = 1\n",
    "y_half[FLAGS.batch_size.value//2:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no = 0\n",
    "stop_training_dis = False\n",
    "class_grad_weight = 0.5\n",
    "target_filter_index = 62\n",
    "reg = 1\n",
    "learning_rate_class = 5e-4\n",
    "conv_layer = layers['conv1_pre_relu']\n",
    "steps = 1\n",
    "noise_coeff = 0\n",
    "to_display = True\n",
    "true_weights = None\n",
    "gradient, target_pixel = find_gradient_multiple_filters(conv_layer, FLAGS.batch_size.value, X)\n",
    "grad_dis = tf.gradients(score_dis, X_dis)[0]\n",
    "n = 10\n",
    "canvas = np.empty((IMAGE_SIZE * n, IMAGE_SIZE * n, 3))    \n",
    "accumulateClassifier = np.zeros((FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "accumulateDiscriminator = np.zeros((FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "noise_img = np.random.rand(FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "img = noise_img\n",
    "accumulateClassifier[:, :, :, :] = 0\n",
    "accumulateDiscriminator[:, :, :, :] = 0\n",
    "loss = []\n",
    "objectives = []\n",
    "for k in range(steps):\n",
    "    for inter_loop in range(10):\n",
    "        print(inter_loop)\n",
    "        class_g, dis_g, activation = sess.run([gradient, grad_dis, target_pixel], feed_dict={X: img, X_dis: img, true_Y_dis: y_real})\n",
    "        # Accumulate and Normalize the gradient\n",
    "        class_grad_reg = class_g - reg*img\n",
    "        dis_grad_reg = dis_g - reg*img\n",
    "        accumulateClassifier = 0.1 * class_grad_reg ** 2 + 0.9 * accumulateClassifier \n",
    "        normalized_class_grad = class_grad_reg / np.sqrt(accumulateClassifier + 1e-8)\n",
    "        accumulateDiscriminator = 0.1 * dis_grad_reg ** 2 + 0.9 * accumulateDiscriminator \n",
    "        normalized_dis_grad = dis_grad_reg / np.sqrt(accumulateDiscriminator + 1e-8)        \n",
    "        # Add the gradient from classifier\n",
    "        noise = np.random.normal(size=(FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "        img += (learning_rate_class) * (normalized_class_grad * class_grad_weight + normalized_dis_grad * (1 - class_grad_weight) + noise_coeff*noise)\n",
    "                    \n",
    "    # Display the image\n",
    "    if (to_display):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                # Draw the generated digits\n",
    "                canvas[i * IMAGE_SIZE:(i + 1) * IMAGE_SIZE, j * IMAGE_SIZE:(j + 1) * IMAGE_SIZE, :] = img[i * n + j]\n",
    "        plt.figure(figsize=(n, n))\n",
    "        plt.imshow(canvas)\n",
    "        plt.show()\n",
    "        print('iter=' + str(k))\n",
    "        print('Class Gradient range  =' + str(np.min(normalized_class_grad)) + \" \" + str(np.max(normalized_class_grad)))\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(0.2)\n",
    "#     if not stop_training_dis:\n",
    "#         train_no+=1\n",
    "#         batch_images = sess.run([true_images])\n",
    "#         # Train Discriminator for two iterations, random mix fake and real image\n",
    "#         first_half = np.append(img[:FLAGS.batch_size.value// 2], batch_images[:FLAGS.batch_size.value// 2], axis = 0)\n",
    "#         second_half = np.append(img[FLAGS.batch_size.value// 2:], batch_images[FLAGS.batch_size.value// 2:], axis = 0)\n",
    "#         first_half_index = np.random.permutation(FLAGS.batch_size.value)\n",
    "#         second_half_index = np.random.permutation(FLAGS.batch_size.value)\n",
    "#         sess.run([train_dis], feed_dict={X_dis: first_half[first_half_index], true_Y_dis: y_half[first_half_index]})\n",
    "#         sess.run([train_dis], feed_dict={X_dis: second_half[second_half_index], true_Y_dis: y_half[second_half_index]})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images = sess.run([true_images])\n",
    "# # Train Discriminator for two iterations, random mix fake and real image\n",
    "# first_half = np.append(img[:FLAGS.batch_size.value// 2], batch_images[:FLAGS.batch_size.value// 2], axis = 0)\n",
    "# second_half = np.append(img[FLAGS.batch_size.value// 2:], batch_images[FLAGS.batch_size.value// 2:], axis = 0)\n",
    "# first_half_index = np.random.permutation(FLAGS.batch_size.value)\n",
    "# second_half_index = np.random.permutation(FLAGS.batch_size.value)\n",
    "# sess.run([train_dis], feed_dict={X_dis: first_half[first_half_index], true_Y_dis: y_half[first_half_index]})\n",
    "# sess.run([train_dis], feed_dict={X_dis: second_half[second_half_index], true_Y_dis: y_half[second_half_index]})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and objective on the same graph\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('iteration (t)')\n",
    "ax1.set_ylabel('losses', color='red')\n",
    "ax1.plot(losses, color='red')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "ax2 = ax1.twinx()  \n",
    "ax2.set_ylabel('objectives', color='blue') \n",
    "ax2.plot(objectives, color='tab:blue')\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "fig.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the second layer\n",
    "target_filter_index = 62\n",
    "re = 1\n",
    "lr = 5e-4\n",
    "img, losses, objectives, canvas = activation_maximization(sess, layers['conv2_pre_relu'], target_filter_index, to_display = True, reg = re, learning_rate_class = lr, steps = 300, noise_coeff = 0)\n",
    "# Get the average gradient descent result of a batch\n",
    "# mean_batch = np.mean(img, axis = 0)\n",
    "# Plot\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.imshow(mean_batch[10:15,10:15,:]*re)\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.imshow(first_layer[:,:,:,target_filter_index])\n",
    "#     plt.savefig('FirstLayerACResultImgs/'+ 'TunningResult/' + 'reg'+str(re)+'lr' +str(lr) +'.jpg')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(canvas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives_log = np.array(np.log(objectives))\n",
    "plt.plot(objectives_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 8\n",
    "h = 16\n",
    "canvas = np.empty((24 * w, 24 * h, 3))\n",
    "# Display by different Batch\n",
    "for filter_index in range(1):\n",
    "    print(filter_index)\n",
    "    for img_index_in_batch in range(128):\n",
    "        pic = img[img_index_in_batch]\n",
    "        for i in range(3):\n",
    "            color_layer = pic[:,:,i]\n",
    "            min_pixel = np.min(color_layer)\n",
    "            max_pixel = np.max(color_layer)\n",
    "            color_layer[color_layer < 0] = 0.5*color_layer[color_layer < 0]/(- min_pixel)\n",
    "            color_layer[color_layer >= 0] = 0.5*color_layer[color_layer >= 0]/max_pixel\n",
    "            color_layer = color_layer + 0.5\n",
    "            # Scale the upper\n",
    "            pic[:,:,i] = color_layer\n",
    "        k = img_index_in_batch // h\n",
    "        p = img_index_in_batch - k*h\n",
    "        canvas[k * 24:(k + 1) * 24, p * 24:(p + 1) * 24, :] = pic\n",
    "    plt.figure(figsize=(w*2, h*2))\n",
    "    plt.imshow(canvas)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(img, axis = 0)[:,:,0],cmap=plt.get_cmap('Greys'))\n",
    "plt.show()\n",
    "plt.imshow(np.mean(img, axis = 0)[:,:,1],cmap=plt.get_cmap('Greys'))\n",
    "plt.show()\n",
    "plt.imshow(np.mean(img, axis = 0)[:,:,2],cmap=plt.get_cmap('Greys'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img = np.mean(img, axis = 0)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(mean_img)\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(mean_img[:,:,0],cmap=plt.get_cmap('Greys'))\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(mean_img[:,:,1],cmap=plt.get_cmap('Greys'))\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(mean_img[:,:,2],cmap=plt.get_cmap('Greys'))\n",
    "plt.show()\n",
    "plt.savefig('SecondLayerACResultImgs/' +str(i) +'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "result_objective = []\n",
    "for target_filter_index in range(64):\n",
    "    img, losses, objectives, canvas = activation_maximization(sess, layers['conv2_pre_relu'], target_filter_index, \n",
    "                                                              reg = 1, learning_rate_class = 1e-3, steps = 300, \n",
    "                                                              noise_coeff = 0)\n",
    "    # Get the average gradient descent result of a batch\n",
    "    results.append(img)\n",
    "    result_objective.append(objectives)\n",
    "    mean_img = np.mean(img, axis = 0)\n",
    "    # Plot\n",
    "    print(target_filter_index)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(mean_img)\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(mean_img[:,:,0],cmap=plt.get_cmap('Greys'))\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(mean_img[:,:,1],cmap=plt.get_cmap('Greys'))\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(mean_img[:,:,2],cmap=plt.get_cmap('Greys'))\n",
    "#     plt.savefig('SecondLayerACResultImgs/' +str(target_filter_index) +'.jpg')\n",
    "    plt.show()\n",
    "results = np.array(results)\n",
    "np.save('SecondLayerAMResultBatch', results)\n",
    "result_objective = np.array(result_objective)\n",
    "np.save('SecondLayerAMResultActivations', result_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "np.save('SecondLayerAMResultBatch', results)\n",
    "result_objective = np.array(result_objective)\n",
    "np.save('SecondLayerAMResultActivations', result_objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some exploration on gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_class in range(10):\n",
    "    ## Check Gredient end-to-end\n",
    "    start = layers['conv2']\n",
    "    end = tf.slice(layers['soft_max_out'], begin=[0, target_class],size=[FLAGS.batch_size.value, 1])\n",
    "    target_grad = tf.gradients(end, start)\n",
    "    ## Run the sess\n",
    "    noise_img = np.random.rand(FLAGS.batch_size.value, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    g = sess.run([target_grad], feed_dict={X: noise_img})\n",
    "    g = g[0][0]\n",
    "    filter_index = 6\n",
    "    target_gradient = g[:,:,:,filter_index]\n",
    "    print(target_class, np.max(target_gradient), np.min(target_gradient), np.mean(target_gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = sess.run(last_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(last_layer[:,5] == np.max(last_layer[:,5] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
